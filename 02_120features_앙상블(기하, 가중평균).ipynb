{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "7-UlwCFXvnhC",
    "outputId": "dd8a4a4f-b473-4e54-f898-862f8c515037",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install catboost\n",
    "#!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "odd9C38GvRC0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\82105\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "%run import_modules.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6KYJiedvRC3"
   },
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qSV21xEjvRC4"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv').drop('index', axis=1)\n",
    "y_train = X_train['voted']\n",
    "X_train = X_train.drop('voted', axis=1)\n",
    "X_test = pd.read_csv('test_x.csv').drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyI0mlNZvRC6"
   },
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsgsZdQVvRC6"
   },
   "source": [
    "## 2-1. 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "57S5xt1gvRC7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45532, 120)\n",
      "(11383, 120)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 이상치제거\n",
    "def to_int32(dataDF):\n",
    "    Answers = dataDF.filter(regex='A').columns.tolist()\n",
    "    \n",
    "    ### float 데이터 -> int로 처리\n",
    "    for feature in Answers:\n",
    "        dataDF[feature] = dataDF[feature].astype('int32') \n",
    "    \n",
    "    dataDF['Q_A_score'] = dataDF[Answers].mean(axis = 1)\n",
    "    return dataDF\n",
    "\n",
    "X_train = to_int32(X_train)\n",
    "X_test = to_int32(X_test)\n",
    "\n",
    "\n",
    "### 스케일링[RobustScaler]\n",
    "robustScaler = RobustScaler()\n",
    "features = X_train.filter(regex='E').columns.tolist()\n",
    "X_train[features] = robustScaler.fit_transform(np.array(X_train[features])) \n",
    "X_test[features] = robustScaler.transform(np.array(X_test[features]))\n",
    "\n",
    "\n",
    "########## 피처 추가 #############\n",
    "# 응답 종류 개수\n",
    "X_train_Q_A = X_train.filter(like = 'A')\n",
    "X_test_Q_A = X_test.filter(like = 'A')\n",
    "X_train['Q_A_count'] = X_train_Q_A.nunique(axis = 1)\n",
    "X_test['Q_A_count'] = X_test_Q_A.nunique(axis = 1)\n",
    "\n",
    "# 응답평균시간\n",
    "X_train_Q_E = X_train.filter(like = 'E')\n",
    "X_test_Q_E = X_test.filter(like = 'E')\n",
    "X_train['Q_E_mean'] = X_train_Q_E.mean(axis = 1)\n",
    "X_test['Q_E_mean'] = X_test_Q_E.mean(axis = 1)\n",
    "\n",
    "# 응답최대시간\n",
    "X_train['Q_E_max'] = X_train_Q_E.max(axis = 1)\n",
    "X_test['Q_E_max'] = X_test_Q_E.max(axis = 1)\n",
    "\n",
    "# wr_(01-13) : 실존하는 해당 단어의 정의을 앎 & wf_(01-03) : 허구인 단어의 정의를 앎\n",
    "# yes = 1, No = 0\n",
    "# 합산을 통해서 얼마나 쌈박하게 똑똑한지\n",
    "X_train_wr = X_train.filter(like = 'wr')\n",
    "X_test_wr = X_test.filter(like = 'wr')\n",
    "X_train_wf = X_train.filter(like = 'wf')\n",
    "X_test_wf = X_test.filter(like = 'wf')\n",
    "X_train['wr_sum'] = X_train_wr.sum(axis = 1)\n",
    "X_test['wr_sum'] = X_test_wr.sum(axis = 1)\n",
    "X_train['wf_sum'] = X_train_wf.sum(axis = 1)\n",
    "X_test['wf_sum'] = X_test_wf.sum(axis = 1)\n",
    "\n",
    "# 응답시간 변동계수\n",
    "X_train['Q_E_cov'] = X_train_Q_E.std(axis = 1)/X_train_Q_E.mean(axis = 1)\n",
    "X_test['Q_E_cov'] = X_test_Q_E.std(axis = 1)/X_test_Q_E.mean(axis = 1)\n",
    "\n",
    "# 응답별 응답비율\n",
    "X_train_total = X_train_Q_E.sum()\n",
    "X_test_total = X_test_Q_E.sum()\n",
    "X_train_Q_E_ratio = X_train_Q_E/X_train_total * 100000 # 단위가 너무 낮아서 100000 곱해줌\n",
    "X_test_Q_E_ratio = X_test_Q_E/X_test_total * 100000\n",
    "X_train_Q_E_ratio = X_train_Q_E_ratio.add_suffix('_ratio')\n",
    "X_test_Q_E_ratio = X_test_Q_E_ratio.add_suffix('_ratio')\n",
    "X_train = pd.concat([X_train, X_train_Q_E_ratio], axis = 1)\n",
    "X_test = pd.concat([X_test, X_test_Q_E_ratio], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "### 인코딩[라벨화]\n",
    "le = LabelEncoder()\n",
    "features = ['age_group','gender']\n",
    "for feature in features:\n",
    "    X_train[feature] = le.fit_transform(np.array(X_train[feature]))\n",
    "    X_test[feature] = le.transform(np.array(X_test[feature]))\n",
    "    \n",
    "    \n",
    "### 인코딩[원핫인코딩]\n",
    "def onehot_cat_features(dataDF):\n",
    "    \n",
    "    dataDF = pd.get_dummies(dataDF, columns = ['race', 'religion'])\n",
    "    \n",
    "    return dataDF\n",
    "\n",
    "X_train = onehot_cat_features(X_train)\n",
    "X_test = onehot_cat_features(X_test)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QRLI4TXvRC8"
   },
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U3X5_2uovRC9"
   },
   "outputs": [],
   "source": [
    "### skf first, sscv later\n",
    "sscv = StratifiedShuffleSplit(n_splits = 4, random_state=24)\n",
    "skf = StratifiedKFold(n_splits=4 , shuffle=True, random_state=24)\n",
    "cv = skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_for_ensemble = [\n",
    "    ('LGBMClassifier', LGBMClassifier(colsample_bytree=0.7604296531524981,\n",
    "               learning_rate=0.02307705418401338, max_depth=26,\n",
    "               min_child_samples=34, min_child_weight=10.666818829880135,\n",
    "               n_estimators=169, num_leaves=39, objective='binary',\n",
    "               subsample=0.8577600405357944), 0.7694156640221028),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier(bootstrap=True, max_depth=14,\n",
    "                     max_features=0.8094388028799028, min_samples_leaf=16,\n",
    "                     min_samples_split=25, n_estimators=161, n_jobs=-1,\n",
    "                     oob_score=True, random_state=0), 0.7708838436513831)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용하지 않을 모델 주석처리\n",
    "models = [\n",
    "    'ExtraTreesClassifier',\n",
    "    'LGBMClassifier',\n",
    "#    'GradientBoostingClassifier',\n",
    "#    'XGBClassifier',\n",
    "#    'CatBoostClassifier'\n",
    "]\n",
    "\n",
    "selected_models = [clf for clf in models_for_ensemble if clf[0] in models]\n",
    "BO_tuned_clfs = selected_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxsRVgVzvRDF"
   },
   "source": [
    "### 3-1. extra, lgb 기하평균, 가중평균\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< LGBMClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7682\n",
      "   2번째 ROC_AUC 0.7667\n",
      "   3번째 ROC_AUC 0.7706\n",
      "   4번째 ROC_AUC 0.7671\n",
      "     평균 정확도: 0.7681\n",
      "< LGBMClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7673\n",
      "   2번째 ROC_AUC 0.7682\n",
      "   3번째 ROC_AUC 0.7737\n",
      "   4번째 ROC_AUC 0.7658\n",
      "     평균 정확도: 0.7687\n",
      "< LGBMClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7683\n",
      "   2번째 ROC_AUC 0.7736\n",
      "   3번째 ROC_AUC 0.7683\n",
      "   4번째 ROC_AUC 0.7668\n",
      "     평균 정확도: 0.7693\n",
      "LGBMClassifier 모델 12개 학습 완료!,  걸린시간: 20.169060230255127초\n",
      "기하평균 csv 파일 출력 완료!\n",
      "< ExtraTreesClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7711\n",
      "   2번째 ROC_AUC 0.7698\n",
      "   3번째 ROC_AUC 0.7713\n",
      "   4번째 ROC_AUC 0.7690\n",
      "     평균 정확도: 0.7703\n",
      "< ExtraTreesClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7689\n",
      "   2번째 ROC_AUC 0.7709\n",
      "   3번째 ROC_AUC 0.7742\n",
      "   4번째 ROC_AUC 0.7660\n",
      "     평균 정확도: 0.7700\n",
      "< ExtraTreesClassifier 학습시작 >\n",
      "   1번째 ROC_AUC 0.7701\n",
      "   2번째 ROC_AUC 0.7744\n",
      "   3번째 ROC_AUC 0.7687\n",
      "   4번째 ROC_AUC 0.7674\n",
      "     평균 정확도: 0.7702\n",
      "ExtraTreesClassifier 모델 12개 학습 완료!,  걸린시간: 149.17559218406677초\n",
      "기하평균 csv 파일 출력 완료!\n"
     ]
    }
   ],
   "source": [
    "### set models & submission name\n",
    "\n",
    "for clf in BO_tuned_clfs:\n",
    "    \n",
    "    model_name = clf[0]\n",
    "    submission_name = '[120features]' + f'{model_name}' + '_12models_gmean.csv'\n",
    "\n",
    "    ### produce folder & save models\n",
    "    model_storage = 'pkl_storage2'\n",
    "    folder_name = model_name\n",
    "    #folder_name = ', '.join([clf[0] for clf in BO_tuned_clfs])\n",
    "    if os.path.exists(f'{model_storage}') == False:\n",
    "        os.mkdir(f'{model_storage}')\n",
    "    if os.path.exists(f'{model_storage}/{folder_name}') == False:\n",
    "        os.mkdir(f'{model_storage}/{folder_name}')\n",
    "        \n",
    "    ### model을 (seed * n_splits)개 찍어서 gmean\n",
    "\n",
    "#    averaging = VotingClassifier(\n",
    "#       estimators = [(clf[0],  clf[1]) for clf in BO_tuned_clfs], voting='soft')\n",
    "    model = clf[1]\n",
    "\n",
    "    start = time.time()\n",
    "    lucky_seed = [1234,24,91]\n",
    "    for seed in lucky_seed:\n",
    "        print(f'< {model_name} 학습시작 >')\n",
    "        skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "        model.random_state = seed\n",
    "        scores = []\n",
    "        for iter_count, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "            X_tra, X_valid = X_train.values[train_index], X_train.values[valid_index]\n",
    "            y_tra, y_valid = y_train.values[train_index], y_train.values[valid_index]\n",
    "\n",
    "            model.fit(X_tra, y_tra)\n",
    "            joblib.dump(model, f'{model_storage}/{folder_name}/{folder_name}_{iter_count}_{seed}.pkl')        \n",
    "\n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            score = roc_auc_score(y_valid, pred)\n",
    "            scores.append(score)\n",
    "            print(f'   {iter_count+1}번째 ROC_AUC {score:.4f}')\n",
    "\n",
    "        mean_score = np.mean(scores)\n",
    "        print(f'     평균 정확도: {mean_score:.4f}') \n",
    "\n",
    "    print(f'{model_name} 모델 {len(lucky_seed) * skf.n_splits}개 학습 완료!,  걸린시간: {time.time() - start}초')\n",
    "\n",
    "    ### load models & predict_proba\n",
    "    models = os.listdir(f'{model_storage}/{folder_name}')\n",
    "    models_list = [x for x in models if x.endswith(\".pkl\")]\n",
    "    assert len(models_list) == 12 # 12개 아니면 error\n",
    "\n",
    "    ### gmean\n",
    "    preds = []\n",
    "    for m in models_list:\n",
    "        model = joblib.load(f'{model_storage}/{folder_name}/'+m)\n",
    "        predict_proba = model.predict_proba(X_test)[:,1]\n",
    "        preds.append(predict_proba)\n",
    "    pred_mean = gmean([each_seed_pred for each_seed_pred in preds])\n",
    "    sub = pd.DataFrame({'index':range(11383), 'voted':pred_mean})\n",
    "    sub.to_csv(f'기하평균 {submission_name}', index=False)\n",
    "    print('기하평균 csv 파일 출력 완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중평균 출력완료!\n",
      "기하평균 출력완료!\n"
     ]
    }
   ],
   "source": [
    "### 모델별 gmean된 파일을 불러와서 평균\n",
    "extra_gmean = pd.read_csv('기하평균 [120features]ExtraTreesClassifier_12models_gmean.csv').voted\n",
    "lgb_gmean = pd.read_csv('기하평균 [120features]LGBMClassifier_12models_gmean.csv').voted\n",
    "submission_name = '[120features] extra, lgb.csv'\n",
    "\n",
    "### 가중평균\n",
    "extra_weight = 0.675; lab_weight = 0.325;\n",
    "pred_mean = (extra_gmean * extra_weight) + (lgb_gmean * lab_weight)\n",
    "sub = pd.DataFrame({'index':range(X_test.shape[0]), 'voted':pred_mean})\n",
    "sub.to_csv(f'가중평균 {submission_name}', index=False)\n",
    "print('가중평균 출력완료!')\n",
    "\n",
    "### 기하평균\n",
    "pred_lst = [extra_gmean, lgb_gmean]\n",
    "pred_mean = gmean(pred_lst)\n",
    "sub = pd.DataFrame({'index':range(X_test.shape[0]), 'voted':pred_mean})\n",
    "sub.to_csv(f'기하평균 {submission_name}', index=False) \n",
    "print('기하평균 출력완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best1_120feature = pd.read_csv('가중평균 [c~AF]extra0.675 + lgb0.325.csv').rename(columns={'voted':'120features'})['120features']\n",
    "#best2_94feature = pd.read_csv('가중평균 [94 features + binning 다르게] extra, lgb.csv').rename(columns={'voted':'94features'})['94features']\n",
    "#best3_155feature = pd.read_csv('기하평균 [1104 + pca] extra, lgb.csv').rename(columns={'voted':'155features'})['155features']\n",
    "\n",
    "#compare_features = [best1_120feature, best2_94feature, best3_155feature]\n",
    "#pd.DataFrame(compare_features).T.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMEAN\n",
    "\n",
    "120features : 0.780688 (현 베스트)   \n",
    "94 features + binning :0.780556    \n",
    "155 features = 1104 + pca : 0.780497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best1_120feature = pd.read_csv('가중평균 [c~AF]extra0.675 + lgb0.325.csv').voted\n",
    "#best2_94feature = pd.read_csv('가중평균 [94 features + binning 다르게] extra, lgb.csv').voted\n",
    "#best3_155feature = pd.read_csv('기하평균 [1104 + pca] extra, lgb.csv').voted\n",
    "\n",
    "#submission_name = '[120, 94, 155 features] extra, lgb.csv'\n",
    "\n",
    "#preds = [best1_120feature, best2_94feature, best3_155feature]\n",
    "#pred_mean = gmean(preds)\n",
    "#sub = pd.DataFrame({'index':range(X_test.shape[0]), 'voted':pred_mean})\n",
    "#sub.to_csv(f'기하평균 {submission_name}', index=False) \n",
    "#print('기하평균 출력완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "09_02 Pipeline(a~d-skf-R(lgb,extra,cat)-seedEnsemble).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
